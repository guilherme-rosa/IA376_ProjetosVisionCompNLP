{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercicio2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uu8IE531RvPz"},"source":["# **Mecanismo de Auto-atenção para Análise de Sentimento Usando o Dataset IMDB**\n","\n","#### **Professores:** Roberto A. Lotufo e Rodrigo F. Nogueira\n","#### **Aluno:** Guilherme Rosa"]},{"cell_type":"markdown","metadata":{"id":"bL2WPSYNSbp8"},"source":["### **1. Imports**"]},{"cell_type":"code","metadata":{"id":"q_o4uxnB9wSR"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","\n","import gensim\n","import gensim.downloader as api\n","\n","import itertools\n","import collections\n","import re\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-U5XQyfTDwb","executionInfo":{"status":"ok","timestamp":1602869836359,"user_tz":180,"elapsed":5497,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"5d3aa8f7-a382-4482-817d-105433362162","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Usando: {device}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Usando: cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CXFdJz2KVeQw"},"source":["### **2. Preparação dos dados**"]},{"cell_type":"markdown","metadata":{"id":"gHMi_Kq65fPM"},"source":["#### **2.1. Download do dataset com amostras de treinamento e validação**"]},{"cell_type":"code","metadata":{"id":"2wbnfzst5O3k","executionInfo":{"status":"ok","timestamp":1602869837034,"user_tz":180,"elapsed":6153,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"62416e11-8beb-47c2-c6c5-8fe71c316ae6","colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["!wget -nc http://files.fast.ai/data/examples/imdb_sample.tgz\n","!tar -xzf imdb_sample.tgz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-10-16 17:34:53--  http://files.fast.ai/data/examples/imdb_sample.tgz\n","Resolving files.fast.ai (files.fast.ai)... 172.67.69.159, 104.26.2.19, 104.26.3.19, ...\n","Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://files.fast.ai/data/examples/imdb_sample.tgz [following]\n","--2020-10-16 17:34:53--  https://files.fast.ai/data/examples/imdb_sample.tgz\n","Connecting to files.fast.ai (files.fast.ai)|172.67.69.159|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 571827 (558K) [application/x-gtar-compressed]\n","Saving to: ‘imdb_sample.tgz’\n","\n","imdb_sample.tgz     100%[===================>] 558.42K  3.50MB/s    in 0.2s    \n","\n","2020-10-16 17:34:53 (3.50 MB/s) - ‘imdb_sample.tgz’ saved [571827/571827]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C7j79cfDToCa"},"source":["#### **2.2. Tratamento dos dados**"]},{"cell_type":"markdown","metadata":{"id":"0Giyi5Rv_NIm"},"source":["Carregando o dataset do arquivo .csv com o Pandas:"]},{"cell_type":"code","metadata":{"id":"0HIN_xLI_TuT","executionInfo":{"status":"ok","timestamp":1602869837036,"user_tz":180,"elapsed":6137,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"9b197a7f-fb03-45eb-a269-332259ff7818","colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["df = pd.read_csv('imdb_sample/texts.csv')\n","df.shape\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>is_valid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>negative</td>\n","      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>positive</td>\n","      <td>This is a extremely well-made film. The acting...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>negative</td>\n","      <td>Every once in a long while a movie will come a...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>positive</td>\n","      <td>Name just says it all. I watched this movie wi...</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>negative</td>\n","      <td>This movie succeeds at being one of the most u...</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label                                               text  is_valid\n","0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n","1  positive  This is a extremely well-made film. The acting...     False\n","2  negative  Every once in a long while a movie will come a...     False\n","3  positive  Name just says it all. I watched this movie wi...     False\n","4  negative  This movie succeeds at being one of the most u...     False"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"S8dfjdJ-AV79"},"source":["Separação das amostras em conjuntos de treinamento e validação:"]},{"cell_type":"code","metadata":{"id":"KCoftmPmAfXE","executionInfo":{"status":"ok","timestamp":1602869837037,"user_tz":180,"elapsed":6120,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"3ddb7d56-7025-41fb-ef7d-bed4669c05dc","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["train = df[df['is_valid'] == False]\n","valid = df[df['is_valid'] == True]\n","\n","print('treino.shape:', train.shape)\n","print('valid.shape:', valid.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["treino.shape: (800, 3)\n","valid.shape: (200, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZHus6FH7DftH"},"source":["Separação das entradas x e os targets y para treinamento do modelo"]},{"cell_type":"code","metadata":{"id":"I2HyoywGDcW8","executionInfo":{"status":"ok","timestamp":1602869837038,"user_tz":180,"elapsed":6101,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"fdb32dd3-0963-4651-8e4b-9d013a600604","colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["X_train = train['text']\n","Y_train_str = train['label']\n","X_valid = valid['text']\n","Y_valid_str = valid['label']\n","\n","print('X_treino.head():\\n', X_train.head())\n","print('Y_treino.head():\\n', Y_train_str.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X_treino.head():\n"," 0    Un-bleeping-believable! Meg Ryan doesn't even ...\n","1    This is a extremely well-made film. The acting...\n","2    Every once in a long while a movie will come a...\n","3    Name just says it all. I watched this movie wi...\n","4    This movie succeeds at being one of the most u...\n","Name: text, dtype: object\n","Y_treino.head():\n"," 0    negative\n","1    positive\n","2    negative\n","3    positive\n","4    negative\n","Name: label, dtype: object\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M2yNXutfEXQ7"},"source":["Conversão das strings \"positive\" e \"negative\" dos targets para valores booleanos True e False:"]},{"cell_type":"code","metadata":{"id":"46RdLFLkEW-X","executionInfo":{"status":"ok","timestamp":1602869839648,"user_tz":180,"elapsed":1071,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"b5cbf19b-3461-4652-c408-8efbb0d40025","colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["mapeamento = {'positive': True, 'negative': False}\n","Y_train = Y_train_str.map(mapeamento)\n","Y_valid = Y_valid_str.map(mapeamento)\n","print(Y_train.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0    False\n","1     True\n","2    False\n","3     True\n","4    False\n","Name: label, dtype: bool\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-7UpkqpxfJyO","executionInfo":{"status":"ok","timestamp":1602869841679,"user_tz":180,"elapsed":1191,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"544f3dba-a5b9-4446-b53e-4b3bf08f56d6","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["type(Y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pandas.core.series.Series"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"N570Kp3jJeFe"},"source":["### **3. Word embeddings e vocabulário**"]},{"cell_type":"markdown","metadata":{"id":"-TiFnMumXcgM"},"source":["#### **3.1. Download dos word embeddings**"]},{"cell_type":"markdown","metadata":{"id":"UxflUUMBzk-k"},"source":["Lista dos modelos disponíveis: https://github.com/RaRe-Technologies/gensim-data#models"]},{"cell_type":"code","metadata":{"id":"ZxYWSFfizpqJ","executionInfo":{"status":"ok","timestamp":1602368505029,"user_tz":180,"elapsed":123969,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"4a549174-3d84-49ef-e2eb-beb63e62e995","colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["word2vec_model = api.load(\"glove-wiki-gigaword-300\")\n","\n","print(word2vec_model.vectors.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["(400000, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9Xp2Fan8K04Y"},"source":["#### **3.2. Criando o vocabulário**\n","\n","O vocabulário vai conter as 400000 palavras nas quais o word2vec foi desenvolvido.\n","\n","Além disso, incluímos um PAD token [PAD] para preencher com id = 400000 as sequências que possuem um número de tokens menor do que o número de tokens nos quais as sequências são truncadas.\n"]},{"cell_type":"code","metadata":{"id":"U2VnCCqBJ6P6","executionInfo":{"status":"ok","timestamp":1602368505032,"user_tz":180,"elapsed":123948,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"a940500d-813b-4ca7-89db-745abf764f07","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["vocab = {word: index for index, word in enumerate(word2vec_model.index2word)}\n","vocab['[PAD]'] = len(vocab)\n","\n","print('Número de palavras no vocabulário:', len(vocab))\n","print(f'20 tokens mais frequentes: {list(itertools.islice(vocab.keys(), 20))}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Número de palavras no vocabulário: 400001\n","20 tokens mais frequentes: ['the', ',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\", 'for', '-', 'that', 'on', 'is', 'was', 'said', 'with', 'he', 'as']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nJ7Fg1iVwyQU"},"source":["#### **3.3. Alterando a matriz do word2vec**\n","Na definição da rede neural (seção 5.1) utilizaremos a camada de Embedding do Pytorch.\n","\n","Para que essa camada funcione corretamente é necessário que a matriz de embedding do word2vec tenha uma linha correspondente ao id do PAD token."]},{"cell_type":"code","metadata":{"id":"MMj4sUAOwrxV","executionInfo":{"status":"ok","timestamp":1602368505659,"user_tz":180,"elapsed":124544,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"d937fb3b-537e-4610-e5be-8e671a4f26f9","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["embedding_pad = np.zeros(shape=(1, word2vec_model.vectors.shape[1]))\n","word2vec_vectors = np.append(word2vec_model.vectors, embedding_pad, axis=0)\n","\n","print(word2vec_vectors.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(400001, 300)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x91E7wqdCggP"},"source":["### **4. Funções de tokenização e truncamento**"]},{"cell_type":"markdown","metadata":{"id":"RpXMGPLHVUCS"},"source":["#### **4.1. Funções de tokenização e de conversão para ids**"]},{"cell_type":"code","metadata":{"id":"OMen-JFKLFCb","executionInfo":{"status":"ok","timestamp":1602368505660,"user_tz":180,"elapsed":124515,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"eef31fce-25a4-4dee-86ec-08d0c139a580","colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["def tokenize(text):\n","    \"\"\" Entrada: frase dada numa variável do tipo string\n","        -------\n","        Saída  : lista de tokens\n","    \"\"\"\n","    # \\w retorna todos os caracteres alfanuméricos e underscore\n","    # \\w+ retorna todas as palavras que contém caracteres alfanuméricos e underscore \n","    return re.findall(r'\\w+', text.lower())\n","\n","def tokens_to_ids(tokens, vocab):\n","    \"\"\" Entrada: lista de tokens e um dicionário com pares token: id\n","        -------\n","        Saída  : lista de ids\n","    \"\"\"\n","    # Se o token não corresponde a nenhuma palavra do vocabulário, ele é desconsiderado.\n","    return [vocab[token] for token in tokens if token in vocab]\n","\n","def tokens_to_ids_batch(texts, vocab):\n","    \"\"\" Entrada: lista de frases\n","        -------\n","        Saída  : lista de listas de ids (cada lista de ids corresponde a uma frase da listas de frase de entrada)\n","    \"\"\"\n","    return [tokens_to_ids(tokenize(text), vocab) for text in texts]\n","        \n","\n","X_train_ids = tokens_to_ids_batch(X_train, vocab)\n","X_valid_ids = tokens_to_ids_batch(X_valid, vocab)\n","\n","print('Primeiro exemplo:')\n","print(X_train[0])\n","print(X_train_ids[0])\n","print(f'Número de tokens da sequência: {len(X_train_ids[0])}')\n","print(Y_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Primeiro exemplo:\n","Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!\n","[750, 101686, 27886, 18719, 3512, 66019, 2159, 151, 662, 71, 3518, 86321, 31906, 1496, 6, 37, 42, 3520, 907, 285, 13339, 71, 8966, 170723, 2050, 109384, 605, 4, 733, 67, 15, 0, 1938, 13, 37, 2926, 2258, 2844, 24126, 102, 921, 3, 1523, 1305, 31, 26, 432, 51, 13, 79155, 83993, 1229, 37, 15, 1681, 21, 0, 1856, 38, 119, 365, 13247, 390, 30, 7, 11962, 3, 65613, 2290, 1135]\n","Número de tokens da sequência: 70\n","False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8bjlWLV_GwIz","executionInfo":{"status":"ok","timestamp":1602368505661,"user_tz":180,"elapsed":124478,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"8ec1eef5-4a38-40b9-9fbe-9ac7ad872dd4","colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["num_tokens = [len(X_train_id) for X_train_id in X_train_ids]\n","_ = plt.hist(num_tokens)\n","plt.title('Número de amostras em função do número de tokens');"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Gp8Nl6sLGgGZ"},"source":["Nota-se no histograma acima que a maior parcela das amostras possuem um número de tokens menor do que 400."]},{"cell_type":"markdown","metadata":{"id":"bwdMgrmIXtOy"},"source":["#### **4.2. Função para truncamento e padding**"]},{"cell_type":"code","metadata":{"id":"GTrW-KGq25GA","executionInfo":{"status":"ok","timestamp":1602368505662,"user_tz":180,"elapsed":124461,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"06b037c6-9bd6-43de-e00a-560e5faea0b6","colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["def truncate_and_pad(batch_word_ids, \n","                     pad_token_id=400000, \n","                     seq_length=64):\n","    \"\"\" Padroniza as listas de ids do batch de entrada para que todas tenham o mesmo número de elementos (seq_length).\n","        \n","        Entrada: listas de listas de ids\n","        -------\n","        Saídas : numpy arrays dos ids e das masks \n","    \"\"\"\n","    # Parte 1: Se o nº de ids > seq_length -> retorna os primeiros seq_length ids (os demais são descartados)\n","    #          Se o nº de ids < seq_length -> não modifica a lista de ids\n","    batch_word_ids = [word_ids[:seq_length] if len(word_ids) > seq_length else word_ids for word_ids in batch_word_ids]\n","    \n","    # Parte 2: Se o nº de ids > seq_length -> não modifica a lista de ids\n","    #          Se o nº de ids < seq_length -> cria uma lista com o número de PAD ids necessários para completar o tamanho da lista\n","    #                                         e concatena ela ao final da lista de ids\n","    batch_word_ids = [word_ids + [pad_token_id for i in range(seq_length - len(word_ids))] if len(word_ids) < seq_length else word_ids for word_ids in batch_word_ids]\n","    batch_word_ids = np.array(batch_word_ids)\n","    \n","    # Parte 3: Cria a mask utilizada na função softmax\n","    mask = batch_word_ids != pad_token_id\n","\n","    return batch_word_ids, mask\n","\n","# Testing\n","texts = ['we like pizza', 'he does not like apples']\n","batch_word_ids = tokens_to_ids_batch(texts, \n","                                     vocab)\n","print(batch_word_ids)\n","batch, mask = truncate_and_pad(batch_word_ids=batch_word_ids, \n","                               pad_token_id=vocab['[PAD]'],\n","                               seq_length=8)\n","\n","print('batch:\\n', batch)\n","print('mask:\\n', mask)\n","print('batch.shape:', batch.shape)\n","print('mask.shape:', mask.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[53, 117, 9388], [18, 260, 36, 117, 13134]]\n","batch:\n"," [[    53    117   9388 400000 400000 400000 400000 400000]\n"," [    18    260     36    117  13134 400000 400000 400000]]\n","mask:\n"," [[ True  True  True False False False False False]\n"," [ True  True  True  True  True False False False]]\n","batch.shape: (2, 8)\n","mask.shape: (2, 8)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GkwCBbe_CSBq"},"source":["### **5. Definição da rede neural com self-attention**\n"]},{"cell_type":"markdown","metadata":{"id":"nBkePWJWFB5y"},"source":["#### **5.1. Definição do modelo SelfAttentionNN**"]},{"cell_type":"code","metadata":{"id":"w1eObN8Qvrut"},"source":["class SelfAttentionNN(nn.Module):\n","    def __init__(self, embeddings, hidden_dim, pad_token_id):\n","        super().__init__()\n","\n","        self.embeddings_vec = embeddings\n","        self.hidden_dim = hidden_dim\n","        self.pad_token_id = pad_token_id\n","        \n","        # Word2vec:\n","        self.embeddings = nn.Embedding.from_pretrained(torch.from_numpy(self.embeddings_vec), freeze=True, padding_idx=self.pad_token_id)\n","        \n","        # Classificador binário:\n","        self.linear = nn.Linear(in_features=self.embeddings_vec.shape[1], out_features=self.hidden_dim)\n","        self.output = nn.Linear(in_features=self.hidden_dim, out_features=2)\n","        \n","    def self_attention(self, q, k, v, mask):\n","        scores = torch.bmm(q, torch.transpose(k, 2, 1))\n","        mask = torch.transpose(mask.unsqueeze(dim=2), 2, 1)\n","        scores = scores.masked_fill(mask == False, -1e9)    # outra forma: mask = mask.expand_as(scores) -> scores[~mask] = -1e9\n","        probs = torch.softmax(scores, dim=-1)\n","        E_batch = torch.bmm(probs, v)\n","        return E_batch\n","\n","    def forward(self, word_ids, mask):\n","        X_emb = self.embeddings(word_ids) # Batch de embeddings\n","        q, k, v = X_emb, X_emb, X_emb\n","        X_emb = self.self_attention(q=q, k=k, v=v, mask=mask) # Calcula as novas representações para os embeddings do batch\n","        X_emb = (X_emb * mask.unsqueeze(2)).sum(1) / torch.clamp(mask.sum(1), min=1).unsqueeze(1)  # Calcula a média dos embeddings por amostra do\n","        hidden = torch.relu(self.linear(X_emb.float()))\n","        logits = self.output(hidden)\n","        return logits\n","\n","    def self_attention_loop(self, seqs, masks):\n","        batch = [] # armazena as sequências do batch com as novas representações\n","        for seq, mask in zip(seqs, masks):  \n","            new_qs = []   # armazena as novas representações para cada sequência do batch\n","            for q in seq:\n","                scores = []  # armazena os scores correspondentes a uma query da sequência\n","                for k, m in zip(seq, mask):\n","                    if m:\n","                        score = torch.sum(q * k)  # produto escalar\n","                    else:\n","                        score = -1e9   # Aplicação da mascara \n","                    scores.append(score)\n","                scores = torch.softmax(torch.from_numpy(np.array(scores)), dim=0) # aplica a softmax\n","                \n","                new_q = torch.zeros_like(q) \n","                for v, score in zip(seq, scores):\n","                    new_q += score * v\n","                new_qs.append(new_q)\n","            \n","            new_qs = torch.stack(new_qs, dim=0)    \n","            batch.append(new_qs)\n","        \n","        batch = torch.stack(batch, dim=0)\n","        return batch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CaHOwU0tnZTp"},"source":["#### **5.2. Verificando o funcionamento do self-attention com loops e o eficiente - Parte 1**"]},{"cell_type":"code","metadata":{"id":"ZkJ6R-pngrAU"},"source":["texts = ['we like pizza', 'he does not like apples']\n","batch_word_ids = tokens_to_ids_batch(texts, \n","                                     vocab)\n","batch, mask = truncate_and_pad(batch_word_ids=batch_word_ids, \n","                               pad_token_id=vocab['[PAD]'],\n","                               seq_length=8)\n","\n","model = SelfAttentionNN(embeddings=word2vec_vectors, hidden_dim=300, pad_token_id=vocab['[PAD]'])\n","seqs_ids = torch.from_numpy(batch)\n","mask = torch.from_numpy(mask)\n","\n","seq_embeddings = model.embeddings(seqs_ids)\n","print(seq_embeddings.shape)\n","print(mask.shape)\n","\n","new_seqs1 = model.self_attention_loop(seq_embeddings, mask)\n","new_seqs2 = model.self_attention(q=seq_embeddings, k=seq_embeddings, v=seq_embeddings, mask=mask)\n","\n","print(new_seqs1.shape)\n","print(new_seqs2.shape)\n","if torch.allclose(new_seqs1, new_seqs2):\n","    print('Ambas as funções chegaram aos mesmos resultados.')\n","else:\n","    print('Os resultados deram diferentes.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QhtQ0n-okWQF"},"source":["#### **5.3. Verificando o funcionamento do self-attention com loops e o eficiente - Parte 2**"]},{"cell_type":"code","metadata":{"id":"bKrBJ9jyQFj0","executionInfo":{"status":"ok","timestamp":1602369038695,"user_tz":180,"elapsed":980,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"902c0ae9-066c-4f1c-8332-b5ade946dfee","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["model = SelfAttentionNN(embeddings=word2vec_vectors, hidden_dim=300, pad_token_id=vocab['[PAD]'])\n","\n","\n","batch, mask = truncate_and_pad(batch_word_ids=X_train_ids[:32], \n","                               pad_token_id=vocab['[PAD]'],\n","                               seq_length=200)\n","seqs_ids = torch.from_numpy(batch)\n","mask = torch.from_numpy(mask)\n","\n","seq_embeddings = model.embeddings(seqs_ids)\n","print(seq_embeddings.shape)\n","print(mask.shape)\n","\n","new_seqs1 = model.self_attention_loop(seq_embeddings, mask)\n","new_seqs2 = model.self_attention(q=seq_embeddings, k=seq_embeddings, v=seq_embeddings, mask=mask)\n","\n","print(new_seqs1.shape)\n","print(new_seqs2.shape)\n","if torch.allclose(new_seqs1, new_seqs2):\n","    print('Ambas as funções chegaram aos mesmos resultados.')\n","else:\n","    print('Os resultados deram diferentes.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 200, 300])\n","torch.Size([32, 200])\n","torch.Size([2, 8, 300])\n","torch.Size([32, 200, 300])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MQFdcww9kpgR"},"source":["### **6. Funções auxiliares**\n"]},{"cell_type":"markdown","metadata":{"id":"sEth9xY2EdO_"},"source":["#### **6.1. Função para retornar mini-batch**"]},{"cell_type":"markdown","metadata":{"id":"Nq0BkzDqMyxp"},"source":["Durante o treinamento de uma rede neural, ao ínves de ajustarmos seus pesos usando todo o dataset de treinamento de uma só vez, é comum usarmos mini-batches, que são apenas algums exemplos amostrados do conjunto de dados. Repetimos isso diversas vezes até termos usado todo o conjunto de treinamento.\n","\n","Para isso precisamos criar uma função que retorna mini-batches. A função abaixo retorna uma lista de listas contento os índices dos exemplos que serão usados em cada mini-batch. Por exemplo, se o dataset contém 6 amostras e o batch size é 2, a função retorna uma lista contendo 3 listas, cada uma contendo 2 índices: `[[4, 2], [3, 5], [0, 1]]`\n"]},{"cell_type":"code","metadata":{"id":"yMb0YooAMyV0"},"source":["def get_minibatches_idx(total_size, batch_size, shuffle):\n","    idx_list = np.arange(total_size, dtype=np.int32)\n","    if shuffle:\n","        np.random.shuffle(idx_list)\n","\n","    minibatches = []\n","    minibatch_start = 0\n","    for i in range(len(idx_list) // batch_size):\n","        minibatches.append(idx_list[minibatch_start:\n","                                    minibatch_start + batch_size])\n","        minibatch_start += batch_size\n","\n","    if (minibatch_start != len(idx_list)):\n","        # Fazemos um minibatch do que restou.\n","        minibatches.append(idx_list[minibatch_start:])\n","\n","    return minibatches"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6X6fVReqECK5"},"source":["#### **6.2. Função de treinamento**"]},{"cell_type":"code","metadata":{"id":"zByG_J6XOhGO"},"source":["@torch.enable_grad()\n","def train(X, Y, model, optimizer, criterion, seqlen):\n","    minibatches = get_minibatches_idx(total_size=len(X), batch_size=16, shuffle=True)\n","\n","    running_loss = 0\n","    running_score = 0\n","    model.train()\n","    for minibatch_idxs in minibatches:\n","        # Retorna as listas de índices e os respectivos targets para o mini-batch:\n","        X_batch = [X[minibatch_idx] for minibatch_idx in minibatch_idxs]\n","        Y_batch = Y[minibatch_idxs]\n","\n","        # Faz a padronização do tamanho das sequências de entrada do modelo:\n","        X_batch, mask = truncate_and_pad(X_batch, seq_length=seqlen, pad_token_id=vocab['[PAD]'])\n","        \n","        # Conversão para tensores:\n","        X_batch = torch.from_numpy(np.array(X_batch, dtype=np.int64)).to(device)\n","        mask = torch.from_numpy(np.array(mask)).to(device)\n","        Y_batch = torch.from_numpy(Y_batch).to(device)\n","\n","        logits = model(word_ids=X_batch, mask=mask)   # Etapa forward\n","        loss = criterion(logits, Y_batch)             # Cálculo da função custo\n","        running_loss += loss                          # Custo acumulado\n","        optimizer.zero_grad()\n","        loss.backward()                               # Etapa backward (cálculo do gradiente)\n","        optimizer.step()                              # Ajuste dos pesos sinápticos do modelo e parâmetros do otimizador\n","        \n","        class_predictons = logits.argmax(dim=1)                # Predições do modelo para as amostras do mini-batch\n","        running_score += (class_predictons == Y_batch).sum()   # Soma o número de predições corretas para o mini-batch\n","\n","    epoch_loss = running_loss.item() / len(minibatches)      # Custo médio da época\n","    epoch_score = running_score.item() / len(X)              # Número de acertos da época\n","    return epoch_loss,epoch_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzK9dPLdExQn"},"source":["#### **6.3. Função de validação**"]},{"cell_type":"code","metadata":{"id":"MqiiLHV9PQ1V"},"source":["@torch.no_grad()\n","def evaluate(X, Y, model, criterion, seqlen):\n","    minibatches = get_minibatches_idx(total_size=len(X), batch_size=32, shuffle=False)\n","    \n","    running_loss = 0\n","    running_score = 0\n","    model.eval()\n","    for minibatch_idxs in minibatches:\n","        # Retorna as listas de índices e os respectivos targets para o mini-batch:\n","        X_batch = [X[minibatch_idx] for minibatch_idx in minibatch_idxs]\n","        Y_batch = Y[minibatch_idxs]\n","\n","        # Faz a padronização do tamanho das sequências de entrada do modelo:\n","        X_batch, mask = truncate_and_pad(X_batch, seq_length=seqlen, pad_token_id=vocab['[PAD]'])\n","\n","        # Conversão para tensores:\n","        X_batch = torch.from_numpy(np.array(X_batch, dtype=np.int64)).to(device)\n","        mask = torch.from_numpy(np.array(mask)).to(device)\n","        Y_batch = torch.from_numpy(Y_batch).to(device)\n","\n","        logits = model(word_ids=X_batch, mask=mask)            # Etapa forward\n","        loss = criterion(logits, Y_batch)                      # Cálculo da função custo\n","        running_loss += loss                                   # Custo acumulado\n","        \n","        class_predictons = logits.argmax(dim=1)                # Predições do modelo para as amostras do mini-batch\n","        running_score += (class_predictons == Y_batch).sum()   # Soma o número de predições corretas para o mini-batch\n","\n","    epoch_loss = running_loss.item() / len(minibatches)         # Custo médio da época\n","    epoch_score = running_score.item() / len(X)                 # Número de acertos da época\n","    return epoch_loss, epoch_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jJ_fYt7nkZ9C"},"source":["#### **6.4. Função para plotar o gráficos da função custo:**"]},{"cell_type":"code","metadata":{"id":"0ZZolfESkaPR"},"source":["def plot_metrics(train_metric, val_metric, metric_name, num):\n","    plt.figure(num)\n","    plt.plot(train_metric, label='Training '+ metric_name)\n","    plt.plot(val_metric, label='Validation ' + metric_name)\n","    plt.title(metric_name.title() + ' vs Epochs')\n","    plt.legend(frameon=False)\n","\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aqmlqf6tENaz"},"source":["### **7. Treinamento do modelo**"]},{"cell_type":"code","metadata":{"id":"92RcHIEONdzB","executionInfo":{"status":"ok","timestamp":1602370048409,"user_tz":180,"elapsed":180799,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"3bbc8bba-521b-4ea7-ad64-9c90405572f3","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["N_EPOCHS = 500\n","\n","model = SelfAttentionNN(embeddings=word2vec_vectors, hidden_dim=300, pad_token_id=vocab['[PAD]']).to(device)\n","optimizer = optim.SGD(model.parameters(), lr=1e-2)\n","criterion = nn.CrossEntropyLoss()\n","\n","if not isinstance(Y_train, np.ndarray):\n","    Y_train = Y_train.to_numpy().astype(np.int64)\n","    Y_valid = Y_valid.to_numpy().astype(np.int64)\n","\n","train_losses = []\n","valid_losses = []\n","for epoch in range(N_EPOCHS):\n","    train_loss, train_acc = train(X=X_train_ids, Y=Y_train, model=model, optimizer=optimizer, criterion=criterion, seqlen=200)\n","    valid_loss, valid_acc = evaluate(X=X_valid_ids, Y=Y_valid, model=model, criterion=criterion, seqlen=200)\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    print(f'epoch: {epoch} '\n","          f'Train loss: {train_loss:.3f} '\n","          f'Train accuracy: {train_acc:.3f} '\n","          f'Valid loss: {valid_loss:.3f} '\n","          f'Valid accuracy: {valid_acc:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 0 Train loss: 0.692 Train accuracy: 0.521 Valid loss: 0.690 Valid accuracy: 0.535\n","epoch: 1 Train loss: 0.692 Train accuracy: 0.521 Valid loss: 0.690 Valid accuracy: 0.535\n","epoch: 2 Train loss: 0.691 Train accuracy: 0.521 Valid loss: 0.689 Valid accuracy: 0.535\n","epoch: 3 Train loss: 0.690 Train accuracy: 0.521 Valid loss: 0.688 Valid accuracy: 0.535\n","epoch: 4 Train loss: 0.690 Train accuracy: 0.521 Valid loss: 0.687 Valid accuracy: 0.535\n","epoch: 5 Train loss: 0.689 Train accuracy: 0.521 Valid loss: 0.687 Valid accuracy: 0.535\n","epoch: 6 Train loss: 0.689 Train accuracy: 0.521 Valid loss: 0.686 Valid accuracy: 0.535\n","epoch: 7 Train loss: 0.688 Train accuracy: 0.521 Valid loss: 0.686 Valid accuracy: 0.535\n","epoch: 8 Train loss: 0.688 Train accuracy: 0.521 Valid loss: 0.685 Valid accuracy: 0.535\n","epoch: 9 Train loss: 0.687 Train accuracy: 0.522 Valid loss: 0.685 Valid accuracy: 0.535\n","epoch: 10 Train loss: 0.687 Train accuracy: 0.522 Valid loss: 0.684 Valid accuracy: 0.540\n","epoch: 11 Train loss: 0.686 Train accuracy: 0.539 Valid loss: 0.683 Valid accuracy: 0.535\n","epoch: 12 Train loss: 0.685 Train accuracy: 0.570 Valid loss: 0.682 Valid accuracy: 0.535\n","epoch: 13 Train loss: 0.685 Train accuracy: 0.532 Valid loss: 0.681 Valid accuracy: 0.535\n","epoch: 14 Train loss: 0.684 Train accuracy: 0.554 Valid loss: 0.681 Valid accuracy: 0.540\n","epoch: 15 Train loss: 0.684 Train accuracy: 0.546 Valid loss: 0.680 Valid accuracy: 0.540\n","epoch: 16 Train loss: 0.683 Train accuracy: 0.583 Valid loss: 0.679 Valid accuracy: 0.535\n","epoch: 17 Train loss: 0.682 Train accuracy: 0.555 Valid loss: 0.679 Valid accuracy: 0.560\n","epoch: 18 Train loss: 0.682 Train accuracy: 0.583 Valid loss: 0.678 Valid accuracy: 0.555\n","epoch: 19 Train loss: 0.681 Train accuracy: 0.542 Valid loss: 0.677 Valid accuracy: 0.585\n","epoch: 20 Train loss: 0.680 Train accuracy: 0.568 Valid loss: 0.676 Valid accuracy: 0.605\n","epoch: 21 Train loss: 0.679 Train accuracy: 0.599 Valid loss: 0.675 Valid accuracy: 0.610\n","epoch: 22 Train loss: 0.679 Train accuracy: 0.614 Valid loss: 0.674 Valid accuracy: 0.590\n","epoch: 23 Train loss: 0.679 Train accuracy: 0.598 Valid loss: 0.673 Valid accuracy: 0.605\n","epoch: 24 Train loss: 0.677 Train accuracy: 0.580 Valid loss: 0.673 Valid accuracy: 0.665\n","epoch: 25 Train loss: 0.677 Train accuracy: 0.621 Valid loss: 0.672 Valid accuracy: 0.635\n","epoch: 26 Train loss: 0.676 Train accuracy: 0.636 Valid loss: 0.671 Valid accuracy: 0.635\n","epoch: 27 Train loss: 0.675 Train accuracy: 0.640 Valid loss: 0.669 Valid accuracy: 0.630\n","epoch: 28 Train loss: 0.674 Train accuracy: 0.623 Valid loss: 0.669 Valid accuracy: 0.670\n","epoch: 29 Train loss: 0.673 Train accuracy: 0.651 Valid loss: 0.668 Valid accuracy: 0.665\n","epoch: 30 Train loss: 0.672 Train accuracy: 0.672 Valid loss: 0.666 Valid accuracy: 0.645\n","epoch: 31 Train loss: 0.671 Train accuracy: 0.629 Valid loss: 0.666 Valid accuracy: 0.715\n","epoch: 32 Train loss: 0.670 Train accuracy: 0.660 Valid loss: 0.665 Valid accuracy: 0.715\n","epoch: 33 Train loss: 0.669 Train accuracy: 0.654 Valid loss: 0.664 Valid accuracy: 0.715\n","epoch: 34 Train loss: 0.668 Train accuracy: 0.674 Valid loss: 0.662 Valid accuracy: 0.680\n","epoch: 35 Train loss: 0.666 Train accuracy: 0.652 Valid loss: 0.662 Valid accuracy: 0.690\n","epoch: 36 Train loss: 0.666 Train accuracy: 0.674 Valid loss: 0.659 Valid accuracy: 0.670\n","epoch: 37 Train loss: 0.664 Train accuracy: 0.660 Valid loss: 0.658 Valid accuracy: 0.705\n","epoch: 38 Train loss: 0.664 Train accuracy: 0.689 Valid loss: 0.657 Valid accuracy: 0.725\n","epoch: 39 Train loss: 0.662 Train accuracy: 0.671 Valid loss: 0.655 Valid accuracy: 0.725\n","epoch: 40 Train loss: 0.661 Train accuracy: 0.666 Valid loss: 0.655 Valid accuracy: 0.680\n","epoch: 41 Train loss: 0.659 Train accuracy: 0.681 Valid loss: 0.653 Valid accuracy: 0.675\n","epoch: 42 Train loss: 0.658 Train accuracy: 0.676 Valid loss: 0.652 Valid accuracy: 0.685\n","epoch: 43 Train loss: 0.657 Train accuracy: 0.694 Valid loss: 0.649 Valid accuracy: 0.705\n","epoch: 44 Train loss: 0.656 Train accuracy: 0.682 Valid loss: 0.648 Valid accuracy: 0.680\n","epoch: 45 Train loss: 0.654 Train accuracy: 0.679 Valid loss: 0.646 Valid accuracy: 0.720\n","epoch: 46 Train loss: 0.652 Train accuracy: 0.689 Valid loss: 0.645 Valid accuracy: 0.685\n","epoch: 47 Train loss: 0.651 Train accuracy: 0.693 Valid loss: 0.644 Valid accuracy: 0.680\n","epoch: 48 Train loss: 0.649 Train accuracy: 0.684 Valid loss: 0.641 Valid accuracy: 0.685\n","epoch: 49 Train loss: 0.649 Train accuracy: 0.688 Valid loss: 0.640 Valid accuracy: 0.710\n","epoch: 50 Train loss: 0.646 Train accuracy: 0.677 Valid loss: 0.638 Valid accuracy: 0.700\n","epoch: 51 Train loss: 0.645 Train accuracy: 0.681 Valid loss: 0.636 Valid accuracy: 0.710\n","epoch: 52 Train loss: 0.643 Train accuracy: 0.686 Valid loss: 0.635 Valid accuracy: 0.690\n","epoch: 53 Train loss: 0.643 Train accuracy: 0.695 Valid loss: 0.635 Valid accuracy: 0.695\n","epoch: 54 Train loss: 0.641 Train accuracy: 0.705 Valid loss: 0.632 Valid accuracy: 0.670\n","epoch: 55 Train loss: 0.638 Train accuracy: 0.696 Valid loss: 0.632 Valid accuracy: 0.705\n","epoch: 56 Train loss: 0.637 Train accuracy: 0.695 Valid loss: 0.631 Valid accuracy: 0.700\n","epoch: 57 Train loss: 0.634 Train accuracy: 0.693 Valid loss: 0.627 Valid accuracy: 0.680\n","epoch: 58 Train loss: 0.634 Train accuracy: 0.689 Valid loss: 0.626 Valid accuracy: 0.690\n","epoch: 59 Train loss: 0.632 Train accuracy: 0.691 Valid loss: 0.625 Valid accuracy: 0.695\n","epoch: 60 Train loss: 0.630 Train accuracy: 0.699 Valid loss: 0.623 Valid accuracy: 0.685\n","epoch: 61 Train loss: 0.628 Train accuracy: 0.696 Valid loss: 0.622 Valid accuracy: 0.695\n","epoch: 62 Train loss: 0.627 Train accuracy: 0.696 Valid loss: 0.621 Valid accuracy: 0.695\n","epoch: 63 Train loss: 0.625 Train accuracy: 0.705 Valid loss: 0.621 Valid accuracy: 0.695\n","epoch: 64 Train loss: 0.623 Train accuracy: 0.701 Valid loss: 0.616 Valid accuracy: 0.690\n","epoch: 65 Train loss: 0.622 Train accuracy: 0.710 Valid loss: 0.615 Valid accuracy: 0.700\n","epoch: 66 Train loss: 0.621 Train accuracy: 0.699 Valid loss: 0.616 Valid accuracy: 0.710\n","epoch: 67 Train loss: 0.619 Train accuracy: 0.703 Valid loss: 0.611 Valid accuracy: 0.700\n","epoch: 68 Train loss: 0.617 Train accuracy: 0.706 Valid loss: 0.609 Valid accuracy: 0.700\n","epoch: 69 Train loss: 0.616 Train accuracy: 0.705 Valid loss: 0.607 Valid accuracy: 0.700\n","epoch: 70 Train loss: 0.612 Train accuracy: 0.704 Valid loss: 0.606 Valid accuracy: 0.705\n","epoch: 71 Train loss: 0.612 Train accuracy: 0.699 Valid loss: 0.604 Valid accuracy: 0.695\n","epoch: 72 Train loss: 0.610 Train accuracy: 0.696 Valid loss: 0.603 Valid accuracy: 0.695\n","epoch: 73 Train loss: 0.608 Train accuracy: 0.714 Valid loss: 0.601 Valid accuracy: 0.705\n","epoch: 74 Train loss: 0.607 Train accuracy: 0.705 Valid loss: 0.599 Valid accuracy: 0.690\n","epoch: 75 Train loss: 0.604 Train accuracy: 0.703 Valid loss: 0.599 Valid accuracy: 0.695\n","epoch: 76 Train loss: 0.604 Train accuracy: 0.713 Valid loss: 0.597 Valid accuracy: 0.700\n","epoch: 77 Train loss: 0.600 Train accuracy: 0.714 Valid loss: 0.596 Valid accuracy: 0.700\n","epoch: 78 Train loss: 0.600 Train accuracy: 0.723 Valid loss: 0.594 Valid accuracy: 0.700\n","epoch: 79 Train loss: 0.599 Train accuracy: 0.706 Valid loss: 0.593 Valid accuracy: 0.705\n","epoch: 80 Train loss: 0.597 Train accuracy: 0.710 Valid loss: 0.591 Valid accuracy: 0.710\n","epoch: 81 Train loss: 0.594 Train accuracy: 0.718 Valid loss: 0.591 Valid accuracy: 0.690\n","epoch: 82 Train loss: 0.591 Train accuracy: 0.718 Valid loss: 0.589 Valid accuracy: 0.690\n","epoch: 83 Train loss: 0.592 Train accuracy: 0.724 Valid loss: 0.587 Valid accuracy: 0.710\n","epoch: 84 Train loss: 0.587 Train accuracy: 0.715 Valid loss: 0.586 Valid accuracy: 0.690\n","epoch: 85 Train loss: 0.588 Train accuracy: 0.714 Valid loss: 0.584 Valid accuracy: 0.720\n","epoch: 86 Train loss: 0.586 Train accuracy: 0.723 Valid loss: 0.584 Valid accuracy: 0.715\n","epoch: 87 Train loss: 0.584 Train accuracy: 0.721 Valid loss: 0.581 Valid accuracy: 0.715\n","epoch: 88 Train loss: 0.583 Train accuracy: 0.716 Valid loss: 0.581 Valid accuracy: 0.725\n","epoch: 89 Train loss: 0.581 Train accuracy: 0.731 Valid loss: 0.579 Valid accuracy: 0.725\n","epoch: 90 Train loss: 0.579 Train accuracy: 0.731 Valid loss: 0.579 Valid accuracy: 0.685\n","epoch: 91 Train loss: 0.577 Train accuracy: 0.724 Valid loss: 0.576 Valid accuracy: 0.720\n","epoch: 92 Train loss: 0.574 Train accuracy: 0.734 Valid loss: 0.575 Valid accuracy: 0.715\n","epoch: 93 Train loss: 0.574 Train accuracy: 0.738 Valid loss: 0.574 Valid accuracy: 0.715\n","epoch: 94 Train loss: 0.570 Train accuracy: 0.736 Valid loss: 0.573 Valid accuracy: 0.730\n","epoch: 95 Train loss: 0.568 Train accuracy: 0.739 Valid loss: 0.571 Valid accuracy: 0.710\n","epoch: 96 Train loss: 0.569 Train accuracy: 0.733 Valid loss: 0.570 Valid accuracy: 0.715\n","epoch: 97 Train loss: 0.564 Train accuracy: 0.740 Valid loss: 0.569 Valid accuracy: 0.740\n","epoch: 98 Train loss: 0.565 Train accuracy: 0.736 Valid loss: 0.569 Valid accuracy: 0.705\n","epoch: 99 Train loss: 0.562 Train accuracy: 0.741 Valid loss: 0.566 Valid accuracy: 0.735\n","epoch: 100 Train loss: 0.561 Train accuracy: 0.744 Valid loss: 0.565 Valid accuracy: 0.710\n","epoch: 101 Train loss: 0.559 Train accuracy: 0.733 Valid loss: 0.566 Valid accuracy: 0.715\n","epoch: 102 Train loss: 0.558 Train accuracy: 0.740 Valid loss: 0.563 Valid accuracy: 0.735\n","epoch: 103 Train loss: 0.555 Train accuracy: 0.738 Valid loss: 0.562 Valid accuracy: 0.710\n","epoch: 104 Train loss: 0.553 Train accuracy: 0.749 Valid loss: 0.563 Valid accuracy: 0.725\n","epoch: 105 Train loss: 0.549 Train accuracy: 0.756 Valid loss: 0.561 Valid accuracy: 0.740\n","epoch: 106 Train loss: 0.550 Train accuracy: 0.743 Valid loss: 0.560 Valid accuracy: 0.740\n","epoch: 107 Train loss: 0.548 Train accuracy: 0.740 Valid loss: 0.558 Valid accuracy: 0.710\n","epoch: 108 Train loss: 0.546 Train accuracy: 0.748 Valid loss: 0.556 Valid accuracy: 0.725\n","epoch: 109 Train loss: 0.545 Train accuracy: 0.749 Valid loss: 0.557 Valid accuracy: 0.720\n","epoch: 110 Train loss: 0.543 Train accuracy: 0.760 Valid loss: 0.555 Valid accuracy: 0.720\n","epoch: 111 Train loss: 0.542 Train accuracy: 0.752 Valid loss: 0.556 Valid accuracy: 0.720\n","epoch: 112 Train loss: 0.536 Train accuracy: 0.749 Valid loss: 0.553 Valid accuracy: 0.745\n","epoch: 113 Train loss: 0.539 Train accuracy: 0.749 Valid loss: 0.552 Valid accuracy: 0.735\n","epoch: 114 Train loss: 0.537 Train accuracy: 0.740 Valid loss: 0.552 Valid accuracy: 0.745\n","epoch: 115 Train loss: 0.536 Train accuracy: 0.752 Valid loss: 0.555 Valid accuracy: 0.730\n","epoch: 116 Train loss: 0.534 Train accuracy: 0.767 Valid loss: 0.550 Valid accuracy: 0.725\n","epoch: 117 Train loss: 0.529 Train accuracy: 0.752 Valid loss: 0.578 Valid accuracy: 0.685\n","epoch: 118 Train loss: 0.534 Train accuracy: 0.754 Valid loss: 0.551 Valid accuracy: 0.735\n","epoch: 119 Train loss: 0.532 Train accuracy: 0.759 Valid loss: 0.546 Valid accuracy: 0.740\n","epoch: 120 Train loss: 0.527 Train accuracy: 0.755 Valid loss: 0.546 Valid accuracy: 0.735\n","epoch: 121 Train loss: 0.525 Train accuracy: 0.761 Valid loss: 0.549 Valid accuracy: 0.715\n","epoch: 122 Train loss: 0.524 Train accuracy: 0.760 Valid loss: 0.544 Valid accuracy: 0.745\n","epoch: 123 Train loss: 0.523 Train accuracy: 0.752 Valid loss: 0.542 Valid accuracy: 0.750\n","epoch: 124 Train loss: 0.525 Train accuracy: 0.759 Valid loss: 0.542 Valid accuracy: 0.745\n","epoch: 125 Train loss: 0.522 Train accuracy: 0.766 Valid loss: 0.542 Valid accuracy: 0.755\n","epoch: 126 Train loss: 0.520 Train accuracy: 0.755 Valid loss: 0.541 Valid accuracy: 0.750\n","epoch: 127 Train loss: 0.517 Train accuracy: 0.769 Valid loss: 0.540 Valid accuracy: 0.745\n","epoch: 128 Train loss: 0.514 Train accuracy: 0.765 Valid loss: 0.539 Valid accuracy: 0.750\n","epoch: 129 Train loss: 0.514 Train accuracy: 0.770 Valid loss: 0.539 Valid accuracy: 0.755\n","epoch: 130 Train loss: 0.512 Train accuracy: 0.761 Valid loss: 0.538 Valid accuracy: 0.755\n","epoch: 131 Train loss: 0.512 Train accuracy: 0.757 Valid loss: 0.541 Valid accuracy: 0.730\n","epoch: 132 Train loss: 0.512 Train accuracy: 0.772 Valid loss: 0.540 Valid accuracy: 0.725\n","epoch: 133 Train loss: 0.507 Train accuracy: 0.770 Valid loss: 0.535 Valid accuracy: 0.755\n","epoch: 134 Train loss: 0.507 Train accuracy: 0.769 Valid loss: 0.535 Valid accuracy: 0.760\n","epoch: 135 Train loss: 0.505 Train accuracy: 0.775 Valid loss: 0.534 Valid accuracy: 0.755\n","epoch: 136 Train loss: 0.503 Train accuracy: 0.775 Valid loss: 0.538 Valid accuracy: 0.755\n","epoch: 137 Train loss: 0.504 Train accuracy: 0.772 Valid loss: 0.537 Valid accuracy: 0.755\n","epoch: 138 Train loss: 0.502 Train accuracy: 0.779 Valid loss: 0.535 Valid accuracy: 0.745\n","epoch: 139 Train loss: 0.498 Train accuracy: 0.780 Valid loss: 0.531 Valid accuracy: 0.760\n","epoch: 140 Train loss: 0.500 Train accuracy: 0.776 Valid loss: 0.531 Valid accuracy: 0.765\n","epoch: 141 Train loss: 0.495 Train accuracy: 0.775 Valid loss: 0.530 Valid accuracy: 0.765\n","epoch: 142 Train loss: 0.492 Train accuracy: 0.779 Valid loss: 0.539 Valid accuracy: 0.725\n","epoch: 143 Train loss: 0.497 Train accuracy: 0.767 Valid loss: 0.529 Valid accuracy: 0.760\n","epoch: 144 Train loss: 0.494 Train accuracy: 0.787 Valid loss: 0.529 Valid accuracy: 0.760\n","epoch: 145 Train loss: 0.492 Train accuracy: 0.791 Valid loss: 0.544 Valid accuracy: 0.725\n","epoch: 146 Train loss: 0.492 Train accuracy: 0.780 Valid loss: 0.528 Valid accuracy: 0.765\n","epoch: 147 Train loss: 0.490 Train accuracy: 0.776 Valid loss: 0.529 Valid accuracy: 0.750\n","epoch: 148 Train loss: 0.488 Train accuracy: 0.785 Valid loss: 0.526 Valid accuracy: 0.765\n","epoch: 149 Train loss: 0.486 Train accuracy: 0.779 Valid loss: 0.526 Valid accuracy: 0.765\n","epoch: 150 Train loss: 0.484 Train accuracy: 0.784 Valid loss: 0.557 Valid accuracy: 0.705\n","epoch: 151 Train loss: 0.488 Train accuracy: 0.785 Valid loss: 0.525 Valid accuracy: 0.775\n","epoch: 152 Train loss: 0.484 Train accuracy: 0.792 Valid loss: 0.551 Valid accuracy: 0.710\n","epoch: 153 Train loss: 0.484 Train accuracy: 0.779 Valid loss: 0.525 Valid accuracy: 0.760\n","epoch: 154 Train loss: 0.482 Train accuracy: 0.777 Valid loss: 0.527 Valid accuracy: 0.750\n","epoch: 155 Train loss: 0.480 Train accuracy: 0.782 Valid loss: 0.523 Valid accuracy: 0.765\n","epoch: 156 Train loss: 0.476 Train accuracy: 0.782 Valid loss: 0.536 Valid accuracy: 0.740\n","epoch: 157 Train loss: 0.482 Train accuracy: 0.781 Valid loss: 0.522 Valid accuracy: 0.765\n","epoch: 158 Train loss: 0.475 Train accuracy: 0.792 Valid loss: 0.542 Valid accuracy: 0.715\n","epoch: 159 Train loss: 0.473 Train accuracy: 0.791 Valid loss: 0.531 Valid accuracy: 0.770\n","epoch: 160 Train loss: 0.475 Train accuracy: 0.784 Valid loss: 0.521 Valid accuracy: 0.775\n","epoch: 161 Train loss: 0.479 Train accuracy: 0.777 Valid loss: 0.529 Valid accuracy: 0.740\n","epoch: 162 Train loss: 0.478 Train accuracy: 0.777 Valid loss: 0.520 Valid accuracy: 0.765\n","epoch: 163 Train loss: 0.471 Train accuracy: 0.799 Valid loss: 0.520 Valid accuracy: 0.775\n","epoch: 164 Train loss: 0.472 Train accuracy: 0.782 Valid loss: 0.523 Valid accuracy: 0.770\n","epoch: 165 Train loss: 0.472 Train accuracy: 0.795 Valid loss: 0.528 Valid accuracy: 0.765\n","epoch: 166 Train loss: 0.472 Train accuracy: 0.796 Valid loss: 0.523 Valid accuracy: 0.750\n","epoch: 167 Train loss: 0.468 Train accuracy: 0.791 Valid loss: 0.518 Valid accuracy: 0.775\n","epoch: 168 Train loss: 0.467 Train accuracy: 0.785 Valid loss: 0.544 Valid accuracy: 0.720\n","epoch: 169 Train loss: 0.472 Train accuracy: 0.790 Valid loss: 0.518 Valid accuracy: 0.785\n","epoch: 170 Train loss: 0.464 Train accuracy: 0.799 Valid loss: 0.522 Valid accuracy: 0.755\n","epoch: 171 Train loss: 0.463 Train accuracy: 0.780 Valid loss: 0.520 Valid accuracy: 0.775\n","epoch: 172 Train loss: 0.466 Train accuracy: 0.791 Valid loss: 0.517 Valid accuracy: 0.770\n","epoch: 173 Train loss: 0.461 Train accuracy: 0.790 Valid loss: 0.518 Valid accuracy: 0.750\n","epoch: 174 Train loss: 0.465 Train accuracy: 0.789 Valid loss: 0.520 Valid accuracy: 0.755\n","epoch: 175 Train loss: 0.461 Train accuracy: 0.796 Valid loss: 0.537 Valid accuracy: 0.725\n","epoch: 176 Train loss: 0.459 Train accuracy: 0.787 Valid loss: 0.519 Valid accuracy: 0.775\n","epoch: 177 Train loss: 0.457 Train accuracy: 0.804 Valid loss: 0.515 Valid accuracy: 0.780\n","epoch: 178 Train loss: 0.456 Train accuracy: 0.792 Valid loss: 0.521 Valid accuracy: 0.750\n","epoch: 179 Train loss: 0.453 Train accuracy: 0.791 Valid loss: 0.522 Valid accuracy: 0.770\n","epoch: 180 Train loss: 0.459 Train accuracy: 0.795 Valid loss: 0.514 Valid accuracy: 0.785\n","epoch: 181 Train loss: 0.454 Train accuracy: 0.794 Valid loss: 0.514 Valid accuracy: 0.770\n","epoch: 182 Train loss: 0.451 Train accuracy: 0.796 Valid loss: 0.523 Valid accuracy: 0.765\n","epoch: 183 Train loss: 0.452 Train accuracy: 0.802 Valid loss: 0.513 Valid accuracy: 0.795\n","epoch: 184 Train loss: 0.449 Train accuracy: 0.801 Valid loss: 0.517 Valid accuracy: 0.775\n","epoch: 185 Train loss: 0.448 Train accuracy: 0.807 Valid loss: 0.513 Valid accuracy: 0.785\n","epoch: 186 Train loss: 0.453 Train accuracy: 0.805 Valid loss: 0.524 Valid accuracy: 0.750\n","epoch: 187 Train loss: 0.451 Train accuracy: 0.801 Valid loss: 0.513 Valid accuracy: 0.780\n","epoch: 188 Train loss: 0.447 Train accuracy: 0.802 Valid loss: 0.517 Valid accuracy: 0.735\n","epoch: 189 Train loss: 0.451 Train accuracy: 0.794 Valid loss: 0.515 Valid accuracy: 0.755\n","epoch: 190 Train loss: 0.445 Train accuracy: 0.801 Valid loss: 0.512 Valid accuracy: 0.795\n","epoch: 191 Train loss: 0.448 Train accuracy: 0.804 Valid loss: 0.511 Valid accuracy: 0.785\n","epoch: 192 Train loss: 0.447 Train accuracy: 0.806 Valid loss: 0.513 Valid accuracy: 0.760\n","epoch: 193 Train loss: 0.446 Train accuracy: 0.795 Valid loss: 0.513 Valid accuracy: 0.775\n","epoch: 194 Train loss: 0.443 Train accuracy: 0.805 Valid loss: 0.511 Valid accuracy: 0.790\n","epoch: 195 Train loss: 0.442 Train accuracy: 0.804 Valid loss: 0.511 Valid accuracy: 0.790\n","epoch: 196 Train loss: 0.444 Train accuracy: 0.801 Valid loss: 0.533 Valid accuracy: 0.725\n","epoch: 197 Train loss: 0.443 Train accuracy: 0.796 Valid loss: 0.516 Valid accuracy: 0.740\n","epoch: 198 Train loss: 0.442 Train accuracy: 0.797 Valid loss: 0.510 Valid accuracy: 0.790\n","epoch: 199 Train loss: 0.446 Train accuracy: 0.796 Valid loss: 0.512 Valid accuracy: 0.780\n","epoch: 200 Train loss: 0.437 Train accuracy: 0.807 Valid loss: 0.544 Valid accuracy: 0.725\n","epoch: 201 Train loss: 0.446 Train accuracy: 0.800 Valid loss: 0.510 Valid accuracy: 0.785\n","epoch: 202 Train loss: 0.437 Train accuracy: 0.804 Valid loss: 0.512 Valid accuracy: 0.740\n","epoch: 203 Train loss: 0.440 Train accuracy: 0.801 Valid loss: 0.514 Valid accuracy: 0.750\n","epoch: 204 Train loss: 0.436 Train accuracy: 0.806 Valid loss: 0.512 Valid accuracy: 0.770\n","epoch: 205 Train loss: 0.441 Train accuracy: 0.802 Valid loss: 0.510 Valid accuracy: 0.785\n","epoch: 206 Train loss: 0.433 Train accuracy: 0.820 Valid loss: 0.517 Valid accuracy: 0.740\n","epoch: 207 Train loss: 0.435 Train accuracy: 0.811 Valid loss: 0.513 Valid accuracy: 0.750\n","epoch: 208 Train loss: 0.434 Train accuracy: 0.806 Valid loss: 0.509 Valid accuracy: 0.780\n","epoch: 209 Train loss: 0.433 Train accuracy: 0.796 Valid loss: 0.512 Valid accuracy: 0.755\n","epoch: 210 Train loss: 0.436 Train accuracy: 0.811 Valid loss: 0.511 Valid accuracy: 0.760\n","epoch: 211 Train loss: 0.431 Train accuracy: 0.811 Valid loss: 0.515 Valid accuracy: 0.775\n","epoch: 212 Train loss: 0.432 Train accuracy: 0.801 Valid loss: 0.511 Valid accuracy: 0.765\n","epoch: 213 Train loss: 0.430 Train accuracy: 0.802 Valid loss: 0.514 Valid accuracy: 0.750\n","epoch: 214 Train loss: 0.427 Train accuracy: 0.818 Valid loss: 0.509 Valid accuracy: 0.775\n","epoch: 215 Train loss: 0.431 Train accuracy: 0.812 Valid loss: 0.511 Valid accuracy: 0.780\n","epoch: 216 Train loss: 0.428 Train accuracy: 0.809 Valid loss: 0.518 Valid accuracy: 0.775\n","epoch: 217 Train loss: 0.427 Train accuracy: 0.804 Valid loss: 0.522 Valid accuracy: 0.770\n","epoch: 218 Train loss: 0.430 Train accuracy: 0.802 Valid loss: 0.507 Valid accuracy: 0.785\n","epoch: 219 Train loss: 0.428 Train accuracy: 0.814 Valid loss: 0.519 Valid accuracy: 0.745\n","epoch: 220 Train loss: 0.430 Train accuracy: 0.799 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 221 Train loss: 0.425 Train accuracy: 0.797 Valid loss: 0.510 Valid accuracy: 0.770\n","epoch: 222 Train loss: 0.418 Train accuracy: 0.812 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 223 Train loss: 0.428 Train accuracy: 0.804 Valid loss: 0.508 Valid accuracy: 0.780\n","epoch: 224 Train loss: 0.423 Train accuracy: 0.826 Valid loss: 0.506 Valid accuracy: 0.780\n","epoch: 225 Train loss: 0.422 Train accuracy: 0.804 Valid loss: 0.512 Valid accuracy: 0.775\n","epoch: 226 Train loss: 0.424 Train accuracy: 0.805 Valid loss: 0.506 Valid accuracy: 0.780\n","epoch: 227 Train loss: 0.419 Train accuracy: 0.816 Valid loss: 0.512 Valid accuracy: 0.755\n","epoch: 228 Train loss: 0.420 Train accuracy: 0.809 Valid loss: 0.513 Valid accuracy: 0.780\n","epoch: 229 Train loss: 0.424 Train accuracy: 0.814 Valid loss: 0.507 Valid accuracy: 0.770\n","epoch: 230 Train loss: 0.429 Train accuracy: 0.802 Valid loss: 0.520 Valid accuracy: 0.775\n","epoch: 231 Train loss: 0.420 Train accuracy: 0.810 Valid loss: 0.541 Valid accuracy: 0.730\n","epoch: 232 Train loss: 0.418 Train accuracy: 0.810 Valid loss: 0.506 Valid accuracy: 0.780\n","epoch: 233 Train loss: 0.414 Train accuracy: 0.816 Valid loss: 0.506 Valid accuracy: 0.780\n","epoch: 234 Train loss: 0.415 Train accuracy: 0.825 Valid loss: 0.507 Valid accuracy: 0.760\n","epoch: 235 Train loss: 0.411 Train accuracy: 0.812 Valid loss: 0.535 Valid accuracy: 0.735\n","epoch: 236 Train loss: 0.421 Train accuracy: 0.810 Valid loss: 0.506 Valid accuracy: 0.780\n","epoch: 237 Train loss: 0.416 Train accuracy: 0.814 Valid loss: 0.507 Valid accuracy: 0.765\n","epoch: 238 Train loss: 0.416 Train accuracy: 0.818 Valid loss: 0.505 Valid accuracy: 0.775\n","epoch: 239 Train loss: 0.412 Train accuracy: 0.819 Valid loss: 0.533 Valid accuracy: 0.735\n","epoch: 240 Train loss: 0.412 Train accuracy: 0.812 Valid loss: 0.504 Valid accuracy: 0.780\n","epoch: 241 Train loss: 0.411 Train accuracy: 0.829 Valid loss: 0.519 Valid accuracy: 0.750\n","epoch: 242 Train loss: 0.409 Train accuracy: 0.828 Valid loss: 0.505 Valid accuracy: 0.785\n","epoch: 243 Train loss: 0.417 Train accuracy: 0.819 Valid loss: 0.538 Valid accuracy: 0.740\n","epoch: 244 Train loss: 0.411 Train accuracy: 0.814 Valid loss: 0.541 Valid accuracy: 0.735\n","epoch: 245 Train loss: 0.411 Train accuracy: 0.824 Valid loss: 0.516 Valid accuracy: 0.750\n","epoch: 246 Train loss: 0.409 Train accuracy: 0.816 Valid loss: 0.507 Valid accuracy: 0.760\n","epoch: 247 Train loss: 0.408 Train accuracy: 0.819 Valid loss: 0.504 Valid accuracy: 0.770\n","epoch: 248 Train loss: 0.412 Train accuracy: 0.819 Valid loss: 0.508 Valid accuracy: 0.765\n","epoch: 249 Train loss: 0.406 Train accuracy: 0.825 Valid loss: 0.518 Valid accuracy: 0.750\n","epoch: 250 Train loss: 0.411 Train accuracy: 0.821 Valid loss: 0.504 Valid accuracy: 0.775\n","epoch: 251 Train loss: 0.407 Train accuracy: 0.814 Valid loss: 0.505 Valid accuracy: 0.770\n","epoch: 252 Train loss: 0.405 Train accuracy: 0.812 Valid loss: 0.505 Valid accuracy: 0.780\n","epoch: 253 Train loss: 0.404 Train accuracy: 0.825 Valid loss: 0.504 Valid accuracy: 0.775\n","epoch: 254 Train loss: 0.407 Train accuracy: 0.821 Valid loss: 0.508 Valid accuracy: 0.765\n","epoch: 255 Train loss: 0.407 Train accuracy: 0.820 Valid loss: 0.505 Valid accuracy: 0.770\n","epoch: 256 Train loss: 0.402 Train accuracy: 0.815 Valid loss: 0.535 Valid accuracy: 0.735\n","epoch: 257 Train loss: 0.405 Train accuracy: 0.815 Valid loss: 0.508 Valid accuracy: 0.780\n","epoch: 258 Train loss: 0.403 Train accuracy: 0.821 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 259 Train loss: 0.404 Train accuracy: 0.819 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 260 Train loss: 0.402 Train accuracy: 0.811 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 261 Train loss: 0.403 Train accuracy: 0.818 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 262 Train loss: 0.402 Train accuracy: 0.820 Valid loss: 0.512 Valid accuracy: 0.755\n","epoch: 263 Train loss: 0.402 Train accuracy: 0.819 Valid loss: 0.517 Valid accuracy: 0.760\n","epoch: 264 Train loss: 0.399 Train accuracy: 0.829 Valid loss: 0.531 Valid accuracy: 0.755\n","epoch: 265 Train loss: 0.408 Train accuracy: 0.819 Valid loss: 0.511 Valid accuracy: 0.785\n","epoch: 266 Train loss: 0.400 Train accuracy: 0.815 Valid loss: 0.528 Valid accuracy: 0.750\n","epoch: 267 Train loss: 0.393 Train accuracy: 0.831 Valid loss: 0.516 Valid accuracy: 0.765\n","epoch: 268 Train loss: 0.401 Train accuracy: 0.812 Valid loss: 0.518 Valid accuracy: 0.750\n","epoch: 269 Train loss: 0.399 Train accuracy: 0.819 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 270 Train loss: 0.396 Train accuracy: 0.838 Valid loss: 0.514 Valid accuracy: 0.770\n","epoch: 271 Train loss: 0.399 Train accuracy: 0.824 Valid loss: 0.504 Valid accuracy: 0.770\n","epoch: 272 Train loss: 0.398 Train accuracy: 0.823 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 273 Train loss: 0.400 Train accuracy: 0.834 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 274 Train loss: 0.393 Train accuracy: 0.829 Valid loss: 0.512 Valid accuracy: 0.755\n","epoch: 275 Train loss: 0.391 Train accuracy: 0.831 Valid loss: 0.519 Valid accuracy: 0.750\n","epoch: 276 Train loss: 0.396 Train accuracy: 0.821 Valid loss: 0.505 Valid accuracy: 0.765\n","epoch: 277 Train loss: 0.392 Train accuracy: 0.834 Valid loss: 0.503 Valid accuracy: 0.775\n","epoch: 278 Train loss: 0.396 Train accuracy: 0.823 Valid loss: 0.531 Valid accuracy: 0.740\n","epoch: 279 Train loss: 0.398 Train accuracy: 0.815 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 280 Train loss: 0.390 Train accuracy: 0.820 Valid loss: 0.503 Valid accuracy: 0.775\n","epoch: 281 Train loss: 0.392 Train accuracy: 0.826 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 282 Train loss: 0.390 Train accuracy: 0.819 Valid loss: 0.504 Valid accuracy: 0.770\n","epoch: 283 Train loss: 0.395 Train accuracy: 0.830 Valid loss: 0.527 Valid accuracy: 0.755\n","epoch: 284 Train loss: 0.393 Train accuracy: 0.828 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 285 Train loss: 0.387 Train accuracy: 0.825 Valid loss: 0.515 Valid accuracy: 0.765\n","epoch: 286 Train loss: 0.388 Train accuracy: 0.833 Valid loss: 0.505 Valid accuracy: 0.765\n","epoch: 287 Train loss: 0.391 Train accuracy: 0.833 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 288 Train loss: 0.397 Train accuracy: 0.823 Valid loss: 0.518 Valid accuracy: 0.765\n","epoch: 289 Train loss: 0.387 Train accuracy: 0.834 Valid loss: 0.507 Valid accuracy: 0.780\n","epoch: 290 Train loss: 0.388 Train accuracy: 0.828 Valid loss: 0.530 Valid accuracy: 0.750\n","epoch: 291 Train loss: 0.397 Train accuracy: 0.819 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 292 Train loss: 0.387 Train accuracy: 0.838 Valid loss: 0.508 Valid accuracy: 0.780\n","epoch: 293 Train loss: 0.382 Train accuracy: 0.829 Valid loss: 0.563 Valid accuracy: 0.740\n","epoch: 294 Train loss: 0.383 Train accuracy: 0.834 Valid loss: 0.513 Valid accuracy: 0.770\n","epoch: 295 Train loss: 0.382 Train accuracy: 0.835 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 296 Train loss: 0.384 Train accuracy: 0.840 Valid loss: 0.514 Valid accuracy: 0.770\n","epoch: 297 Train loss: 0.384 Train accuracy: 0.839 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 298 Train loss: 0.384 Train accuracy: 0.829 Valid loss: 0.517 Valid accuracy: 0.750\n","epoch: 299 Train loss: 0.387 Train accuracy: 0.829 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 300 Train loss: 0.380 Train accuracy: 0.835 Valid loss: 0.524 Valid accuracy: 0.760\n","epoch: 301 Train loss: 0.385 Train accuracy: 0.825 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 302 Train loss: 0.376 Train accuracy: 0.841 Valid loss: 0.528 Valid accuracy: 0.750\n","epoch: 303 Train loss: 0.388 Train accuracy: 0.821 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 304 Train loss: 0.380 Train accuracy: 0.834 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 305 Train loss: 0.380 Train accuracy: 0.828 Valid loss: 0.504 Valid accuracy: 0.770\n","epoch: 306 Train loss: 0.382 Train accuracy: 0.834 Valid loss: 0.502 Valid accuracy: 0.765\n","epoch: 307 Train loss: 0.382 Train accuracy: 0.824 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 308 Train loss: 0.379 Train accuracy: 0.834 Valid loss: 0.517 Valid accuracy: 0.770\n","epoch: 309 Train loss: 0.379 Train accuracy: 0.826 Valid loss: 0.512 Valid accuracy: 0.760\n","epoch: 310 Train loss: 0.378 Train accuracy: 0.836 Valid loss: 0.511 Valid accuracy: 0.765\n","epoch: 311 Train loss: 0.375 Train accuracy: 0.826 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 312 Train loss: 0.387 Train accuracy: 0.831 Valid loss: 0.519 Valid accuracy: 0.770\n","epoch: 313 Train loss: 0.380 Train accuracy: 0.835 Valid loss: 0.509 Valid accuracy: 0.765\n","epoch: 314 Train loss: 0.377 Train accuracy: 0.836 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 315 Train loss: 0.375 Train accuracy: 0.838 Valid loss: 0.526 Valid accuracy: 0.755\n","epoch: 316 Train loss: 0.380 Train accuracy: 0.829 Valid loss: 0.505 Valid accuracy: 0.765\n","epoch: 317 Train loss: 0.374 Train accuracy: 0.840 Valid loss: 0.512 Valid accuracy: 0.775\n","epoch: 318 Train loss: 0.377 Train accuracy: 0.834 Valid loss: 0.514 Valid accuracy: 0.760\n","epoch: 319 Train loss: 0.376 Train accuracy: 0.830 Valid loss: 0.520 Valid accuracy: 0.755\n","epoch: 320 Train loss: 0.374 Train accuracy: 0.839 Valid loss: 0.505 Valid accuracy: 0.770\n","epoch: 321 Train loss: 0.373 Train accuracy: 0.835 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 322 Train loss: 0.376 Train accuracy: 0.820 Valid loss: 0.539 Valid accuracy: 0.755\n","epoch: 323 Train loss: 0.372 Train accuracy: 0.845 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 324 Train loss: 0.372 Train accuracy: 0.839 Valid loss: 0.507 Valid accuracy: 0.765\n","epoch: 325 Train loss: 0.376 Train accuracy: 0.831 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 326 Train loss: 0.377 Train accuracy: 0.831 Valid loss: 0.516 Valid accuracy: 0.775\n","epoch: 327 Train loss: 0.374 Train accuracy: 0.831 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 328 Train loss: 0.372 Train accuracy: 0.841 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 329 Train loss: 0.373 Train accuracy: 0.849 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 330 Train loss: 0.377 Train accuracy: 0.821 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 331 Train loss: 0.368 Train accuracy: 0.836 Valid loss: 0.521 Valid accuracy: 0.755\n","epoch: 332 Train loss: 0.375 Train accuracy: 0.840 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 333 Train loss: 0.370 Train accuracy: 0.834 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 334 Train loss: 0.372 Train accuracy: 0.829 Valid loss: 0.516 Valid accuracy: 0.770\n","epoch: 335 Train loss: 0.371 Train accuracy: 0.836 Valid loss: 0.512 Valid accuracy: 0.765\n","epoch: 336 Train loss: 0.359 Train accuracy: 0.849 Valid loss: 0.505 Valid accuracy: 0.770\n","epoch: 337 Train loss: 0.369 Train accuracy: 0.834 Valid loss: 0.544 Valid accuracy: 0.725\n","epoch: 338 Train loss: 0.369 Train accuracy: 0.841 Valid loss: 0.503 Valid accuracy: 0.765\n","epoch: 339 Train loss: 0.365 Train accuracy: 0.848 Valid loss: 0.503 Valid accuracy: 0.770\n","epoch: 340 Train loss: 0.357 Train accuracy: 0.848 Valid loss: 0.518 Valid accuracy: 0.770\n","epoch: 341 Train loss: 0.369 Train accuracy: 0.844 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 342 Train loss: 0.360 Train accuracy: 0.853 Valid loss: 0.539 Valid accuracy: 0.760\n","epoch: 343 Train loss: 0.374 Train accuracy: 0.845 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 344 Train loss: 0.363 Train accuracy: 0.855 Valid loss: 0.507 Valid accuracy: 0.775\n","epoch: 345 Train loss: 0.369 Train accuracy: 0.840 Valid loss: 0.513 Valid accuracy: 0.765\n","epoch: 346 Train loss: 0.375 Train accuracy: 0.846 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 347 Train loss: 0.365 Train accuracy: 0.841 Valid loss: 0.532 Valid accuracy: 0.730\n","epoch: 348 Train loss: 0.366 Train accuracy: 0.833 Valid loss: 0.504 Valid accuracy: 0.765\n","epoch: 349 Train loss: 0.360 Train accuracy: 0.831 Valid loss: 0.535 Valid accuracy: 0.760\n","epoch: 350 Train loss: 0.364 Train accuracy: 0.845 Valid loss: 0.559 Valid accuracy: 0.745\n","epoch: 351 Train loss: 0.361 Train accuracy: 0.835 Valid loss: 0.525 Valid accuracy: 0.760\n","epoch: 352 Train loss: 0.365 Train accuracy: 0.840 Valid loss: 0.509 Valid accuracy: 0.770\n","epoch: 353 Train loss: 0.367 Train accuracy: 0.844 Valid loss: 0.507 Valid accuracy: 0.770\n","epoch: 354 Train loss: 0.363 Train accuracy: 0.845 Valid loss: 0.579 Valid accuracy: 0.715\n","epoch: 355 Train loss: 0.369 Train accuracy: 0.845 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 356 Train loss: 0.362 Train accuracy: 0.845 Valid loss: 0.504 Valid accuracy: 0.760\n","epoch: 357 Train loss: 0.363 Train accuracy: 0.836 Valid loss: 0.529 Valid accuracy: 0.760\n","epoch: 358 Train loss: 0.360 Train accuracy: 0.855 Valid loss: 0.534 Valid accuracy: 0.730\n","epoch: 359 Train loss: 0.362 Train accuracy: 0.834 Valid loss: 0.507 Valid accuracy: 0.775\n","epoch: 360 Train loss: 0.367 Train accuracy: 0.843 Valid loss: 0.505 Valid accuracy: 0.765\n","epoch: 361 Train loss: 0.361 Train accuracy: 0.843 Valid loss: 0.512 Valid accuracy: 0.760\n","epoch: 362 Train loss: 0.367 Train accuracy: 0.846 Valid loss: 0.505 Valid accuracy: 0.765\n","epoch: 363 Train loss: 0.365 Train accuracy: 0.845 Valid loss: 0.522 Valid accuracy: 0.755\n","epoch: 364 Train loss: 0.357 Train accuracy: 0.840 Valid loss: 0.508 Valid accuracy: 0.765\n","epoch: 365 Train loss: 0.361 Train accuracy: 0.845 Valid loss: 0.511 Valid accuracy: 0.760\n","epoch: 366 Train loss: 0.359 Train accuracy: 0.844 Valid loss: 0.506 Valid accuracy: 0.770\n","epoch: 367 Train loss: 0.352 Train accuracy: 0.853 Valid loss: 0.504 Valid accuracy: 0.760\n","epoch: 368 Train loss: 0.358 Train accuracy: 0.844 Valid loss: 0.513 Valid accuracy: 0.765\n","epoch: 369 Train loss: 0.356 Train accuracy: 0.849 Valid loss: 0.510 Valid accuracy: 0.775\n","epoch: 370 Train loss: 0.358 Train accuracy: 0.845 Valid loss: 0.514 Valid accuracy: 0.760\n","epoch: 371 Train loss: 0.361 Train accuracy: 0.833 Valid loss: 0.506 Valid accuracy: 0.760\n","epoch: 372 Train loss: 0.358 Train accuracy: 0.843 Valid loss: 0.543 Valid accuracy: 0.730\n","epoch: 373 Train loss: 0.361 Train accuracy: 0.845 Valid loss: 0.541 Valid accuracy: 0.755\n","epoch: 374 Train loss: 0.352 Train accuracy: 0.840 Valid loss: 0.520 Valid accuracy: 0.760\n","epoch: 375 Train loss: 0.353 Train accuracy: 0.848 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 376 Train loss: 0.353 Train accuracy: 0.848 Valid loss: 0.505 Valid accuracy: 0.765\n","epoch: 377 Train loss: 0.355 Train accuracy: 0.850 Valid loss: 0.534 Valid accuracy: 0.765\n","epoch: 378 Train loss: 0.360 Train accuracy: 0.838 Valid loss: 0.507 Valid accuracy: 0.765\n","epoch: 379 Train loss: 0.353 Train accuracy: 0.851 Valid loss: 0.512 Valid accuracy: 0.770\n","epoch: 380 Train loss: 0.356 Train accuracy: 0.844 Valid loss: 0.555 Valid accuracy: 0.750\n","epoch: 381 Train loss: 0.355 Train accuracy: 0.844 Valid loss: 0.520 Valid accuracy: 0.765\n","epoch: 382 Train loss: 0.359 Train accuracy: 0.849 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 383 Train loss: 0.352 Train accuracy: 0.835 Valid loss: 0.507 Valid accuracy: 0.765\n","epoch: 384 Train loss: 0.351 Train accuracy: 0.850 Valid loss: 0.509 Valid accuracy: 0.765\n","epoch: 385 Train loss: 0.362 Train accuracy: 0.845 Valid loss: 0.506 Valid accuracy: 0.760\n","epoch: 386 Train loss: 0.360 Train accuracy: 0.850 Valid loss: 0.530 Valid accuracy: 0.735\n","epoch: 387 Train loss: 0.353 Train accuracy: 0.840 Valid loss: 0.509 Valid accuracy: 0.765\n","epoch: 388 Train loss: 0.350 Train accuracy: 0.840 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 389 Train loss: 0.350 Train accuracy: 0.844 Valid loss: 0.520 Valid accuracy: 0.750\n","epoch: 390 Train loss: 0.346 Train accuracy: 0.854 Valid loss: 0.507 Valid accuracy: 0.770\n","epoch: 391 Train loss: 0.344 Train accuracy: 0.860 Valid loss: 0.508 Valid accuracy: 0.765\n","epoch: 392 Train loss: 0.355 Train accuracy: 0.848 Valid loss: 0.516 Valid accuracy: 0.770\n","epoch: 393 Train loss: 0.342 Train accuracy: 0.851 Valid loss: 0.511 Valid accuracy: 0.765\n","epoch: 394 Train loss: 0.366 Train accuracy: 0.841 Valid loss: 0.530 Valid accuracy: 0.760\n","epoch: 395 Train loss: 0.353 Train accuracy: 0.845 Valid loss: 0.524 Valid accuracy: 0.765\n","epoch: 396 Train loss: 0.350 Train accuracy: 0.848 Valid loss: 0.509 Valid accuracy: 0.755\n","epoch: 397 Train loss: 0.357 Train accuracy: 0.848 Valid loss: 0.508 Valid accuracy: 0.770\n","epoch: 398 Train loss: 0.345 Train accuracy: 0.856 Valid loss: 0.535 Valid accuracy: 0.770\n","epoch: 399 Train loss: 0.355 Train accuracy: 0.853 Valid loss: 0.530 Valid accuracy: 0.760\n","epoch: 400 Train loss: 0.358 Train accuracy: 0.844 Valid loss: 0.509 Valid accuracy: 0.755\n","epoch: 401 Train loss: 0.345 Train accuracy: 0.851 Valid loss: 0.515 Valid accuracy: 0.765\n","epoch: 402 Train loss: 0.352 Train accuracy: 0.845 Valid loss: 0.523 Valid accuracy: 0.740\n","epoch: 403 Train loss: 0.346 Train accuracy: 0.853 Valid loss: 0.510 Valid accuracy: 0.770\n","epoch: 404 Train loss: 0.344 Train accuracy: 0.846 Valid loss: 0.521 Valid accuracy: 0.740\n","epoch: 405 Train loss: 0.354 Train accuracy: 0.848 Valid loss: 0.509 Valid accuracy: 0.765\n","epoch: 406 Train loss: 0.351 Train accuracy: 0.849 Valid loss: 0.509 Valid accuracy: 0.765\n","epoch: 407 Train loss: 0.344 Train accuracy: 0.853 Valid loss: 0.509 Valid accuracy: 0.770\n","epoch: 408 Train loss: 0.351 Train accuracy: 0.848 Valid loss: 0.509 Valid accuracy: 0.765\n","epoch: 409 Train loss: 0.340 Train accuracy: 0.851 Valid loss: 0.558 Valid accuracy: 0.755\n","epoch: 410 Train loss: 0.345 Train accuracy: 0.851 Valid loss: 0.515 Valid accuracy: 0.765\n","epoch: 411 Train loss: 0.350 Train accuracy: 0.854 Valid loss: 0.510 Valid accuracy: 0.765\n","epoch: 412 Train loss: 0.341 Train accuracy: 0.845 Valid loss: 0.531 Valid accuracy: 0.760\n","epoch: 413 Train loss: 0.340 Train accuracy: 0.844 Valid loss: 0.535 Valid accuracy: 0.765\n","epoch: 414 Train loss: 0.340 Train accuracy: 0.861 Valid loss: 0.530 Valid accuracy: 0.760\n","epoch: 415 Train loss: 0.343 Train accuracy: 0.851 Valid loss: 0.511 Valid accuracy: 0.765\n","epoch: 416 Train loss: 0.347 Train accuracy: 0.843 Valid loss: 0.515 Valid accuracy: 0.760\n","epoch: 417 Train loss: 0.344 Train accuracy: 0.850 Valid loss: 0.529 Valid accuracy: 0.765\n","epoch: 418 Train loss: 0.343 Train accuracy: 0.853 Valid loss: 0.512 Valid accuracy: 0.765\n","epoch: 419 Train loss: 0.343 Train accuracy: 0.851 Valid loss: 0.521 Valid accuracy: 0.745\n","epoch: 420 Train loss: 0.339 Train accuracy: 0.858 Valid loss: 0.512 Valid accuracy: 0.760\n","epoch: 421 Train loss: 0.339 Train accuracy: 0.848 Valid loss: 0.521 Valid accuracy: 0.770\n","epoch: 422 Train loss: 0.349 Train accuracy: 0.855 Valid loss: 0.513 Valid accuracy: 0.760\n","epoch: 423 Train loss: 0.340 Train accuracy: 0.854 Valid loss: 0.512 Valid accuracy: 0.765\n","epoch: 424 Train loss: 0.340 Train accuracy: 0.859 Valid loss: 0.591 Valid accuracy: 0.750\n","epoch: 425 Train loss: 0.342 Train accuracy: 0.849 Valid loss: 0.520 Valid accuracy: 0.745\n","epoch: 426 Train loss: 0.338 Train accuracy: 0.853 Valid loss: 0.520 Valid accuracy: 0.765\n","epoch: 427 Train loss: 0.342 Train accuracy: 0.853 Valid loss: 0.517 Valid accuracy: 0.760\n","epoch: 428 Train loss: 0.334 Train accuracy: 0.850 Valid loss: 0.518 Valid accuracy: 0.760\n","epoch: 429 Train loss: 0.343 Train accuracy: 0.848 Valid loss: 0.512 Valid accuracy: 0.760\n","epoch: 430 Train loss: 0.349 Train accuracy: 0.849 Valid loss: 0.515 Valid accuracy: 0.760\n","epoch: 431 Train loss: 0.343 Train accuracy: 0.846 Valid loss: 0.513 Valid accuracy: 0.765\n","epoch: 432 Train loss: 0.334 Train accuracy: 0.860 Valid loss: 0.514 Valid accuracy: 0.760\n","epoch: 433 Train loss: 0.333 Train accuracy: 0.863 Valid loss: 0.520 Valid accuracy: 0.745\n","epoch: 434 Train loss: 0.337 Train accuracy: 0.858 Valid loss: 0.523 Valid accuracy: 0.740\n","epoch: 435 Train loss: 0.334 Train accuracy: 0.851 Valid loss: 0.525 Valid accuracy: 0.740\n","epoch: 436 Train loss: 0.348 Train accuracy: 0.846 Valid loss: 0.514 Valid accuracy: 0.760\n","epoch: 437 Train loss: 0.341 Train accuracy: 0.853 Valid loss: 0.515 Valid accuracy: 0.765\n","epoch: 438 Train loss: 0.335 Train accuracy: 0.856 Valid loss: 0.516 Valid accuracy: 0.760\n","epoch: 439 Train loss: 0.342 Train accuracy: 0.848 Valid loss: 0.524 Valid accuracy: 0.775\n","epoch: 440 Train loss: 0.346 Train accuracy: 0.843 Valid loss: 0.514 Valid accuracy: 0.770\n","epoch: 441 Train loss: 0.341 Train accuracy: 0.844 Valid loss: 0.536 Valid accuracy: 0.760\n","epoch: 442 Train loss: 0.338 Train accuracy: 0.848 Valid loss: 0.515 Valid accuracy: 0.760\n","epoch: 443 Train loss: 0.336 Train accuracy: 0.864 Valid loss: 0.513 Valid accuracy: 0.770\n","epoch: 444 Train loss: 0.329 Train accuracy: 0.851 Valid loss: 0.527 Valid accuracy: 0.740\n","epoch: 445 Train loss: 0.346 Train accuracy: 0.840 Valid loss: 0.578 Valid accuracy: 0.760\n","epoch: 446 Train loss: 0.340 Train accuracy: 0.841 Valid loss: 0.544 Valid accuracy: 0.765\n","epoch: 447 Train loss: 0.346 Train accuracy: 0.843 Valid loss: 0.542 Valid accuracy: 0.735\n","epoch: 448 Train loss: 0.345 Train accuracy: 0.849 Valid loss: 0.557 Valid accuracy: 0.720\n","epoch: 449 Train loss: 0.342 Train accuracy: 0.849 Valid loss: 0.516 Valid accuracy: 0.760\n","epoch: 450 Train loss: 0.330 Train accuracy: 0.859 Valid loss: 0.514 Valid accuracy: 0.765\n","epoch: 451 Train loss: 0.337 Train accuracy: 0.856 Valid loss: 0.535 Valid accuracy: 0.760\n","epoch: 452 Train loss: 0.331 Train accuracy: 0.853 Valid loss: 0.573 Valid accuracy: 0.765\n","epoch: 453 Train loss: 0.336 Train accuracy: 0.855 Valid loss: 0.515 Valid accuracy: 0.765\n","epoch: 454 Train loss: 0.336 Train accuracy: 0.871 Valid loss: 0.519 Valid accuracy: 0.760\n","epoch: 455 Train loss: 0.338 Train accuracy: 0.856 Valid loss: 0.540 Valid accuracy: 0.755\n","epoch: 456 Train loss: 0.338 Train accuracy: 0.858 Valid loss: 0.516 Valid accuracy: 0.765\n","epoch: 457 Train loss: 0.330 Train accuracy: 0.856 Valid loss: 0.526 Valid accuracy: 0.765\n","epoch: 458 Train loss: 0.342 Train accuracy: 0.854 Valid loss: 0.541 Valid accuracy: 0.760\n","epoch: 459 Train loss: 0.340 Train accuracy: 0.848 Valid loss: 0.515 Valid accuracy: 0.755\n","epoch: 460 Train loss: 0.340 Train accuracy: 0.843 Valid loss: 0.518 Valid accuracy: 0.770\n","epoch: 461 Train loss: 0.333 Train accuracy: 0.854 Valid loss: 0.524 Valid accuracy: 0.760\n","epoch: 462 Train loss: 0.337 Train accuracy: 0.845 Valid loss: 0.516 Valid accuracy: 0.755\n","epoch: 463 Train loss: 0.323 Train accuracy: 0.845 Valid loss: 0.516 Valid accuracy: 0.755\n","epoch: 464 Train loss: 0.329 Train accuracy: 0.854 Valid loss: 0.533 Valid accuracy: 0.775\n","epoch: 465 Train loss: 0.329 Train accuracy: 0.863 Valid loss: 0.517 Valid accuracy: 0.765\n","epoch: 466 Train loss: 0.342 Train accuracy: 0.855 Valid loss: 0.516 Valid accuracy: 0.750\n","epoch: 467 Train loss: 0.326 Train accuracy: 0.864 Valid loss: 0.517 Valid accuracy: 0.750\n","epoch: 468 Train loss: 0.328 Train accuracy: 0.854 Valid loss: 0.551 Valid accuracy: 0.760\n","epoch: 469 Train loss: 0.332 Train accuracy: 0.865 Valid loss: 0.559 Valid accuracy: 0.760\n","epoch: 470 Train loss: 0.336 Train accuracy: 0.849 Valid loss: 0.552 Valid accuracy: 0.760\n","epoch: 471 Train loss: 0.331 Train accuracy: 0.850 Valid loss: 0.525 Valid accuracy: 0.755\n","epoch: 472 Train loss: 0.325 Train accuracy: 0.873 Valid loss: 0.532 Valid accuracy: 0.770\n","epoch: 473 Train loss: 0.336 Train accuracy: 0.856 Valid loss: 0.524 Valid accuracy: 0.755\n","epoch: 474 Train loss: 0.335 Train accuracy: 0.845 Valid loss: 0.518 Valid accuracy: 0.750\n","epoch: 475 Train loss: 0.326 Train accuracy: 0.853 Valid loss: 0.522 Valid accuracy: 0.750\n","epoch: 476 Train loss: 0.324 Train accuracy: 0.863 Valid loss: 0.522 Valid accuracy: 0.760\n","epoch: 477 Train loss: 0.334 Train accuracy: 0.865 Valid loss: 0.521 Valid accuracy: 0.755\n","epoch: 478 Train loss: 0.325 Train accuracy: 0.861 Valid loss: 0.525 Valid accuracy: 0.755\n","epoch: 479 Train loss: 0.338 Train accuracy: 0.853 Valid loss: 0.536 Valid accuracy: 0.770\n","epoch: 480 Train loss: 0.333 Train accuracy: 0.848 Valid loss: 0.519 Valid accuracy: 0.755\n","epoch: 481 Train loss: 0.335 Train accuracy: 0.864 Valid loss: 0.531 Valid accuracy: 0.765\n","epoch: 482 Train loss: 0.326 Train accuracy: 0.866 Valid loss: 0.655 Valid accuracy: 0.715\n","epoch: 483 Train loss: 0.337 Train accuracy: 0.846 Valid loss: 0.519 Valid accuracy: 0.750\n","epoch: 484 Train loss: 0.337 Train accuracy: 0.849 Valid loss: 0.522 Valid accuracy: 0.755\n","epoch: 485 Train loss: 0.327 Train accuracy: 0.858 Valid loss: 0.547 Valid accuracy: 0.760\n","epoch: 486 Train loss: 0.334 Train accuracy: 0.845 Valid loss: 0.556 Valid accuracy: 0.755\n","epoch: 487 Train loss: 0.327 Train accuracy: 0.861 Valid loss: 0.531 Valid accuracy: 0.735\n","epoch: 488 Train loss: 0.335 Train accuracy: 0.856 Valid loss: 0.523 Valid accuracy: 0.760\n","epoch: 489 Train loss: 0.326 Train accuracy: 0.860 Valid loss: 0.529 Valid accuracy: 0.750\n","epoch: 490 Train loss: 0.324 Train accuracy: 0.859 Valid loss: 0.541 Valid accuracy: 0.735\n","epoch: 491 Train loss: 0.325 Train accuracy: 0.866 Valid loss: 0.545 Valid accuracy: 0.725\n","epoch: 492 Train loss: 0.322 Train accuracy: 0.863 Valid loss: 0.569 Valid accuracy: 0.765\n","epoch: 493 Train loss: 0.333 Train accuracy: 0.861 Valid loss: 0.536 Valid accuracy: 0.735\n","epoch: 494 Train loss: 0.323 Train accuracy: 0.858 Valid loss: 0.581 Valid accuracy: 0.765\n","epoch: 495 Train loss: 0.328 Train accuracy: 0.858 Valid loss: 0.521 Valid accuracy: 0.745\n","epoch: 496 Train loss: 0.324 Train accuracy: 0.854 Valid loss: 0.525 Valid accuracy: 0.765\n","epoch: 497 Train loss: 0.330 Train accuracy: 0.850 Valid loss: 0.560 Valid accuracy: 0.760\n","epoch: 498 Train loss: 0.321 Train accuracy: 0.868 Valid loss: 0.611 Valid accuracy: 0.755\n","epoch: 499 Train loss: 0.335 Train accuracy: 0.856 Valid loss: 0.561 Valid accuracy: 0.755\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oczK1evwkFgX","executionInfo":{"status":"ok","timestamp":1602370049081,"user_tz":180,"elapsed":128847,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"7476e473-b55a-4cd0-cdb6-543e31c9a3e2","colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["plot_metrics(train_losses, valid_losses, 'loss', 1)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Ydp88f7Ioj35"},"source":["### **8. Métricas pedidas no exercício:**"]},{"cell_type":"markdown","metadata":{"id":"RLLONlzsotr-"},"source":["#### **8.1. Tempo de execução de 1 laço de treinamento e o tempo médio por amostra:**"]},{"cell_type":"code","metadata":{"id":"2eMb-WuIo5eW","executionInfo":{"status":"ok","timestamp":1602208895208,"user_tz":180,"elapsed":185923,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"6cec0b11-3fa5-4a12-86d4-e67172e61ece","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["model = SelfAttentionNN(embeddings=word2vec_vectors, hidden_dim=300, pad_token_id=vocab['[PAD]']).to(device)\n","optimizer = optim.SGD(model.parameters(), lr=1e-2)\n","criterion = nn.CrossEntropyLoss()\n","\n","start_time = time.time()\n","train_loss, train_acc = train(X=X_train_ids, Y=Y_train, model=model, optimizer=optimizer, criterion=criterion)\n","end_time = time.time()\n","loop_time = end_time - start_time\n","\n","print(f'Tempo de execução de 1 laço de treinamento: {loop_time*1000} ms.')\n","print(f'Tempo médio para processar 1 amostra: {loop_time*1000/len(X_train_ids)} ms.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tempo de execução de 1 laço de treinamento: 105.07774353027344 ms.\n","Tempo médio para processar 1 amostra: 0.1313471794128418 ms.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gg0PToEOridW"},"source":["#### **8.2. Acurácia junto aos dados de validação após o treinamento:**"]},{"cell_type":"code","metadata":{"id":"laJ62os4rof0","executionInfo":{"status":"ok","timestamp":1602208895209,"user_tz":180,"elapsed":185913,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"81e65686-7656-40f2-b83c-bbba9e77fe03","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f'Acurácia na validação: {valid_acc*100}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Acurácia na validação: 55.50000000000001%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hwOLc-kYrxyc"},"source":["#### **8.3. Número de parâmetros ajustáveis do modelo:**"]},{"cell_type":"code","metadata":{"id":"KWZOl_-fsBsj","executionInfo":{"status":"ok","timestamp":1602208895210,"user_tz":180,"elapsed":185900,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"bed73cf7-88f9-4cfe-aea7-7c281d4f6e1a","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["num_params = [params.numel() for params in list(model.parameters())]\n","print(f'Número de parâmetros totais (incluindo os não treináveis do word2vec: {num_params}')\n","num_params = np.sum(np.array(num_params[1::]))\n","print(f'Número de parâmetros treináveis do modelo: {num_params}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Número de parâmetros totais (incluindo os não treináveis do word2vec: [120000300, 90000, 300, 600, 2]\n","Número de parâmetros treináveis do modelo: 90902\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"smZ5gLxdteo1"},"source":["#### **8.4. Número de parâmetros ajustáveis do modelo:**"]},{"cell_type":"code","metadata":{"id":"wX-CaLJVt80N","executionInfo":{"status":"ok","timestamp":1602208895211,"user_tz":180,"elapsed":185886,"user":{"displayName":"Guilherme Rosa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh36nCwMfmg6yeBf1jaF6SEh_6qcfAuRsqgwJ8R8A=s64","userId":"04886257781986524516"}},"outputId":"f7745e76-1989-49ba-f828-d787b2730b0a","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["print(f'Número de palavras por amostra: 64')\n","print(f'Embedding size: {word2vec_model.vector_size}')\n","print(f'Batch size de treinamento: 16')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Número de palavras por amostra: 64\n","Embedding size: 300\n","Batch size de treinamento: 16\n"],"name":"stdout"}]}]}